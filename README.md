# AI项目课程代码仓库
##  *基于概率扩散模型的图像生成算法*
###   ————项目成员：温志森、邓实诚、张亮、许培炫、施楷鑫
开源代码仓库：https://github.com/dome272/Diffusion-Models-pytorch
关于diffusion-model原理和代码介绍：
1. https://zhuanlan.zhihu.com/p/610505558
2. https://zhuanlan.zhihu.com/p/572161541
3. https://zhuanlan.zhihu.com/p/577778277

我们的项目是diffusion-model，这个模型的输入是噪声向量，输出是去除噪声后生成的图片。但是如果我们最后用于答辩的成果仅仅只是运行这个仓库的话太过于简单和单调，对于人数为5个人的我们小组来说工作量太小，并且也没有什么让人眼前一亮的点，估计最后给分会不如其他小组。

所以我们在这个模型的基础上进行创新：根据一段文本描述生成图片，这个技术在OpenAI于2022年推出的全新模型*DALL·E 2*中已经实现，它可以根据一段文本描述生成高质量图片。与以往的图片生成模型不同，DALL·E 2可以将多个概念、属性和样式进行组合，生成更具创意性和多样性的图像。例如，DALL·E 2可以生成机器人飞行员驾驶着一辆彩虹色的电动车的图像。它还可以生成多种风格的图片，如写实主义、卡通风格等。DALL·E 2基于GPT-3的预训练技术，使用了2.5万亿个参数进行训练，并且具有更好的泛化能力，可以生成各种复杂场景下的高质量图片。

下面我们的任务就是看相关的资料，理解diffusion-model的相关原理，运行*DALL·E 2*的开源代码（我们之前跟老师说了仅仅生成风景照，是否需要将原有diffusion-model的风景照开源仓库移植到*DALL·E 2*中，使其只能生成风景照？如果是的话，这个就是我们的实验方案，对外宣称我们借鉴了openAI生成模型的技术，在原有diffusion-model的代码的基础上，实现了文字生成图片的功能）

下面是关于*DALL·E 2*的资源：
1. 开源仓库: https://github.com/lucidrains/DALLE2-pytorch
2. 官方网站：https://openai.com/product/dall-e-2
3. diffusion-model在DALL·E 2中的应用：https://en.wikipedia.org/wiki/Diffusion_model

最后答辩希望所有人都能清楚代码的运行逻辑，在老师提出相关问题时能根据技术理解正确回答出来。
能够理解并运行这个项目不仅仅是为了应付课程，也可以扩充自己的知识面（这个可能是比GAN模型更先进的东西），以后也可以用在各种项目中，大家加油！
